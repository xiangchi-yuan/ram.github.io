<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Behavior Knowledge Merge in Reinforced Agentic Models: A framework for merging RL-trained agents.">
  <meta name="keywords" content="Reinforcement Learning, Model Merging, LLM, Agentic Models, RAM">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Behavior Knowledge Merge in Reinforced Agentic Models</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://xiangchi-yuan.github.io/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://github.com/xiangchi-yuan/ram">
            RAM Project
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          
          <h1 class="title is-1 publication-title">Behavior Knowledge Merge in Reinforced Agentic Models</h1>
          
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://xiangchi-yuan.github.io/" target="_blank">Xiangchi Yuan</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://dachuanshi.com/" target="_blank">Dachuan Shi</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://chunhuizng.github.io/" target="_blank">Chunhui Zhang</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://franciscoliu.github.io/" target="_blank">Zheyuan Liu</a><sup>3</sup>,</span><br>
            <span class="author-block">
              <a href="https://james-yaoshenglong.github.io/home/" target="_blank">Shenglong Yao</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.cs.dartmouth.edu/~soroush/" target="_blank">Soroush Vosoughi</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://wenke.gtisc.gatech.edu/" target="_blank">Wenke Lee</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Georgia Institute of Technology,</span>
            <span class="author-block"><sup>2</sup>Dartmouth College,</span>
            <span class="author-block"><sup>3</sup>University of Notre Dame</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><small>xyuan300@gatech.edu</small></span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2601.13572" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2601.13572" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/xiangchi-yuan/mrl" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>

      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
             <br>
             <img src="./static/images/teaser.png" 
                  alt="Teaser Image" 
                  style="width: 100%; border-radius: 10px; box-shadow: 0 0 20px rgba(0,0,0,0.1);"/>
             <h2 class="subtitle has-text-centered" style="margin-top: 15px;">
               <b>Figure 1:</b> RAM merges behaviors from multiple specialized RL agents into a single generalist agent by preserving unique task vectors.
             </h2>
          </div>
        </div>
      </div>
      </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        
        <div class="content has-text-justified" style="background-color: #eef6fc; padding: 1.5rem; border-radius: 10px; margin-bottom: 1.5rem;">
          <p>
            <b>TL;DR:</b> We propose <strong>RAM (Reinforced Agent Merging)</strong>, a new framework to merge RL-trained agents. Unlike SFT merging, RAM explicitly preserves "unique" parameter updates that encode task-specific behaviors, preventing the performance dilution common in standard averaging methods.
          </p>
        </div>

        <div class="content has-text-justified">
          <p>
            Reinforcement learning (RL) is central to post-training, particularly for agentic models that require specialized reasoning behaviors. In this setting, model merging offers a practical mechanism for integrating multiple RL-trained agents from different tasks into a single generalist model. However, existing merging methods are designed for supervised fine-tuning (SFT), and they are suboptimal to preserve task-specific capabilities on RL-trained agentic models. 
          </p>
          <p>
            The root is a task-vector mismatch between RL and SFT: on-policy RL induces task vectors that are highly sparse and heterogeneous, whereas SFT-style merging implicitly assumes dense and globally comparable task vectors. When standard global averaging is applied under this mismatch, RL's non-overlapping task vectors that encode critical task-specific behaviors are reduced and parameter updates are diluted. 
          </p>
          <p>
            To address this issue, we propose Reinforced Agent Merging (RAM), a distribution-aware merging framework explicitly designed for RL-trained agentic models. RAM disentangles shared and task-specific unique parameter updates, averaging shared components while selectively preserving and rescaling unique ones to counteract parameter update dilution. Experiments across multiple agent domains and model architectures demonstrate that RAM not only surpasses merging baselines, but also unlocks synergistic potential among agents to achieve performance superior to that of specialized agents in their domains.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Motivations</h2>
        
        <div class="content has-text-justified">
          <h3 class="title is-4">1. Heterogeneity in Reinforced Task Vectors</h3>
          <p>
            Existing model merging methods typically assume that task vectors are dense and globally comparable (similar to SFT updates). However, our analysis reveals a critical <b>mismatch</b> between these assumptions and the nature of Reinforcement Learning (RL).
            As shown in <b>Figure 2</b>, RL-induced task vectors exhibit extreme <b>sparsity</b> and <b>heterogeneity</b>. For instance, the coding agent modifies only 3.2% of parameters, whereas memory agents update over 54%. More importantly, these updates are distributed across disparate regions of the parameter space, creating unique, non-overlapping patterns for different capabilities.
          </p>
        </div>

        <div class="content">
          <img src="./static/images/motivation1.png" alt="Heterogeneity in Sparsity and Distribution" style="width: 100%; margin-bottom: 10px;"/>
          <p class="subtitle is-6">
            <b>Figure 2:</b> <b>Left:</b> Reinforced task vectors exhibit varying degrees of sparsity across different agents (Code, Tool, Memory). <b>Right:</b> The non-zero elements of these vectors are distributed heterogeneously, with significant portions being "unique" to specific tasks rather than shared.
          </p>
        </div>

        <br>

        <div class="content has-text-justified">
          <h3 class="title is-4">2. The "Signal Dilution" Problem</h3>
          <p>
            Why do standard merging methods fail in this regime? The culprit is a phenomenon we term <b>Signal Dilution</b>. 
            Standard methods rely on global averaging (e.g., <code>1/N</code>). When an agent has a "unique" update for a specific parameter (while others do not), averaging divides this critical signal by the number of models, effectively treating the zero-updates from other agents as valid data. 
            <b>Figure 3</b> demonstrates the impact of this dilution. Unique regions drive significant performance gains (orange bars). However, when we simulate standard averaging by diluting these unique vectors (teal bars), the performance drops sharply. This necessitates a method like RAM, which can disentangle and preserve these unique signals.
          </p>
        </div>

        <div class="content">
          <img src="./static/images/motivation2.png" alt="Signal Dilution Analysis" style="width: 80%; margin-bottom: 10px;"/>
          <p class="subtitle is-6">
            <b>Figure 3:</b> Analysis of <b>Signal Dilution</b>. The "unique" regions of task vectors (orange) are critical for domain-specific performance (e.g., Coding). Applying standard averaging dilutes these signals (teal), causing significant performance regression across all domains.
          </p>
        </div>

      </div>
    </div>
  </div>
</section>

  
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
        <div class="content has-text-justified">
          <p>
            Our framework, <b>Reinforced Agent Merging (RAM)</b>, addresses the task-vector mismatch between RL and SFT. 
            The pipeline consists of three main steps:
          </p>
          
          <img src="./static/images/ram.png" alt="Method Pipeline" style="width: 100%; margin: 20px 0;"/>
          
          <p>
            1. <b>Disentanglement:</b> We separate shared knowledge (common across agents) from unique knowledge (task-specific).<br>
            2. <b>Selective Preservation:</b> Instead of global averaging, we apply a mask to preserve the magnitude of unique updates.<br>
            3. <b>Rescaling:</b> Parameters are rescaled to ensure the merged model retains the specialized capabilities of the original agents.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>





<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3 has-text-centered">Results</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
          <img src="./static/images/result1.png" alt="Visualization 1"/>
          <h2 class="subtitle has-text-centered">
            Main results of agent merging. We evaluate the capabilities across three domains: Coding (LiveBench, LiveCodeBench), Tool Use (Live, Non-Live), and Memory (RULER-HotpotQA, RULER-SQuAD). Bold and underlined values denote the best and second-best performance among merged models, respectively. Cells highlighted in red indicate the best performance across all evaluated models, including the specialized Task Models.
          </h2>
        </div>
        <div class="item">
          <img src="./static/images/result2.png" alt="Visualization 2"/>
          <h2 class="subtitle has-text-centered">
            The performances of merging two agents across domains.
          </h2>
        </div>
        <div class="item">
          <img src="./static/images/result3.png" alt="Visualization 3"/>
          <h2 class="subtitle has-text-centered">
            Merging results for RL agents trained from Llama3.2-3B-Instruction base model.
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>
      <iframe src="./static/pdfs/sample.pdf" width="100%" height="550">
      </iframe>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{yuan2026ram,
  title={Behavior Knowledge Merge in Reinforced Agentic Models},
  author={Yuan, Xiangchi and Shi, Dachuan and Zhang, Chunhui and Liu, Zheyuan and Yao, Shenglong and Vosoughi, Soroush and Lee, Wenke},
  journal={arXiv preprint arXiv:26XX.XXXXX},
  year={2026}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/pdfs/paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/xiangchi-yuan" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This page was adapted from the <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> project page.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
